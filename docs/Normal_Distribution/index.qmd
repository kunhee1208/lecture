---
title: "정규분포(Normal Distribution)"
author: "Kunhee Lee"
format:
  revealjs: 
    theme: default
    logo: "zarathu_eng.png"
    footer: "www.zarathu.com"
    self-contained: false
    chalkboard: 
      buttons: false
    preview-links: true
    show-notes: false
    slide-number: false
    width: 1600
    height: 900
editor: visual
editor_options: 
  chunk_output_type: console
---

## HEADLINE

<center>

**정규분포의 당위성**

> by **이항분포**

> by **오차의 법칙**

> by **중심극한정리**

> 시행 횟수/표본 개수 $n$이 커질수록 **표본평균** $\bar{X}$는 $N(\mu,\frac{\sigma^2}{n})$을 따른다.

</center>

## Contents

1)  Intro

2)  이항분포의 근사

3)  오차의 법칙: 오차라면 마땅히 가지고 있어야 할 조건

4)  중심극한정리: 모양이 일그러진 동전 / 주사위 던지기

5)  중심극한정리: 표준정규분포 / 카이제곱분포

6)  중심극한정리 고찰

7)  Conclusion

## 1. Intro

-   본 챕터에서는 통계학의 기본이 되는 **정규분포(Normal distribution)**의 당위성을 이해하는 것을 목표로 한다.

-   통계 분석을 하다 보면 연속된 값을 갖는 수치에 대해 정규분포를 가정하곤 한다.

-   실제로 키, 몸무게, 시험 점수 등 대다수의 측정값은 정규분포를 따른다.

-   무엇이 정규분포에게 이렇게 막강한 지위를 부여했을까?

-   **이항분포의 근사, 오차의 법칙, 중심극한정리**를 통해 그 이유를 알아보도록 하자.

## 2. 이항분포(Binomial Distribution)

-   **이항분포** $B(n,p)$ : 확률이 $p$인 사건을 $n$번 시행한 사건들의 확률이 따르는 분포
-   **평균:** $np$, 분산: $np(1-p)$임이 잘 알려져 있다.
-   이항분포는 우리 주변의 온갖 사건들을 설명할 수 있다.
-   따라서 정규분포가 이항분포의 근사값으로 표현된다면, 정규분포 또한 세상의 많은 일을 설명할 수 있는 분포가 된다.
-   **이항분포**로부터 **정규분포**까지의 흐름을 살펴보자.

## 2. 이항분포의 근사(1) : 동전을 무한히 던지면?

```{r,echo=F,fig.cap=" 이항분포 VS 정규분포: 동전 던지기",fig.width=12,fig.height=8,warning=F}
library(ggplot2);library(gridExtra)
coin_plot=function(n=10,xl=c(0,10)){
  bin=1:n
  coinplot=ggplot(data.frame(bin,p=dbinom(bin,max(bin),0.5)),aes(bin,p))+geom_bar(stat = "identity",width=0.7)+xlab("앞면 횟수")+ylab("확률")+ggtitle(paste("동전 ",max(bin),"번 던지기",sep=""))+xlim(xl)+theme(plot.title = element_text(hjust = 0.5))+theme(axis.text.x = element_text(size=15,face='bold'))
  return(coinplot)
}

z=seq(450,550)
nplot=ggplot(data.frame(z,p=dnorm(z,mean=500,sd=sqrt(250))),aes(z,p))+geom_line()+ggtitle(expression(paste("정규분포: ",italic(N)(500,250),sep="")))+xlab(expression(z))+ylab("Density")+theme(plot.title = element_text(hjust = 0.5))+theme(axis.text.x = element_text(size=15,face='bold'))

grid.arrange(coin_plot(100,xl=c(30,70)),coin_plot(500,xl=c(215,285)),coin_plot(1000,xl=c(450,550)),nplot, ncol=2)

```

## 2. 이항분포의 근사(2) : 주사위를 무한히 던지면?

```{r,echo=F,fig.cap=" 이항분포 VS 정규분포: 주사위 던지기",fig.width=12,fig.height=8,warning=F}
ju_plot=function(n=10,xl=c(0,10)){
  bin=1:n
  coinplot=ggplot(data.frame(bin,p=dbinom(bin,max(bin),1/6)),aes(bin,p))+geom_bar(stat = "identity",width=0.7)+xlab("1이 나온 횟수")+ylab("확률")+ggtitle(paste("주사위 ",max(bin),"번 던지기",sep=""))+xlim(xl)+theme(plot.title = element_text(hjust = 0.5))+theme(axis.text.x = element_text(size=15,face='bold'))
  return(coinplot)
}

ju_plot2=function(n=10,xl=c(0,10)){
  bin=1:n
  coinplot=ggplot(data.frame(bin,p=dbinom(bin,max(bin),1/6)),aes(bin,p))+geom_bar(stat = "identity",width=0.7)+xlab("1이 나온 횟수")+ylab("확률")+ggtitle(paste("주사위 ",max(bin),"번 던지기",sep=""))+xlim(xl)+theme(plot.title = element_text(hjust = 0.5))+theme(axis.text.x = element_text(size=15,face='bold'))+scale_x_continuous(breaks=c(0,2,4,6,8,10))
  return(coinplot)
}

z=seq(60,140)
jnplot=ggplot(data.frame(z,p=dnorm(z,mean=100,sd=sqrt(250/3))),aes(z,p))+geom_line()+ggtitle(expression(paste("정규분포: ",italic(N)(100,83.3),sep="")))+xlab(expression(z))+ylab("Density")+theme(plot.title = element_text(hjust = 0.5))+theme(axis.text.x = element_text(size=15,face='bold'))

grid.arrange(ju_plot2(10,xl=c(0,10)),ju_plot(60,xl=c(0,20)),ju_plot(600,xl=c(60,140)),jnplot, ncol=2)

```

## 2. 이항분포의 근사(3) : 일반화

-   동전과 주사위 예시를 이항분포와 정규분포의 표현으로 기술해보자.

    -   $B(1000,\frac{1}{2})$는 $N(1000\times \frac{1}{2}, 1000\times \frac{1}{2} \times \frac{1}{2})$ 와 거의 같다.
    -   $B(600,\frac{1}{6})$는 $N(600\times \frac{1}{6}, 600\times \frac{1}{6} \times \frac{5}{6})$와 거의 같다.

-   시행횟수가 커질수록 정규분포에 가까워질 것이라고 예상할 수 있다.

    -   시행횟수 $n$이 커질수록 $B(n,\frac{1}{2})$는 $N(n \times \frac{1}{2}, n \times \frac{1}{2} \times \frac{1}{2})$에 근사한다.
    -   시행횟수 $n$이 커질수록 $B(n,\frac{1}{6})$는 $N(n \times \frac{1}{6}, n \times \frac{1}{6} \times \frac{5}{6})$에 근사한다.

-   예상을 종합하면,

    -   **시행횟수** $n$이 커질수록 $B(n,p)$는 $N(np, np(1-p))$에 근사한다.
    -   정규분포가 이항분포의 근사로 설명되므로 정규분포 역시 대부분의 사건을 설명할 수 있는 지위를 갖는다.

## 3. 오차의 법칙: 오차라면 마땅히 지켜야 할 조건

-   수학자 Gauss는 **오차에 대한 고찰**을 통해 정규분포를 유도했다.
    -   

        1.  +오차와 -오차가 나올 가능성이 같다 -\> $f$는 $f(-\epsilon)=f(\epsilon)$인 좌우대칭 함수

    -   

        2.  오차의 절댓값이 작을수록 나올 가능성이 크다 -\> $f(\epsilon)$는 위로 볼록한 모양

    -   

        3.  $f(\epsilon)$는 2번 미분 가능하고, 확률의 합은 1이다 -\> $\int_{-\infty}^{\infty} f(\epsilon) d\epsilon=1$

    -   

        4.  참값의 MLE는 측정값의 평균이다\
            -\> 측정값이 각각 $x_1, x_2, \cdots, x_n$일 때 가능도 $L=f(x_1-\mu)f(x_2-\mu)\dots f(x_n-\mu)$는 $\mu=\frac{x_1+x_2+\cdots+x_n}{n}$에서 최대
-   위의 조건들을 통해 정규분포의 확률밀도함수를 수학적으로 유도할 수 있고, 결국 정규분포가 세상의 온갖 측정값을 설명하는 중요한 분포라는 결론에 이르게 된다.

## 4. 중심극한정리: 무조건 정규분포 OK?

-   평균은 집단을 비교 및 평가하는 데 가장 흔히 쓰이는 지표이다.
-   우리는 흔히 **표본평균(Sample mean)**을 전체의 평균으로 여기곤 한다.
-   고작 수백, 수천 명의 여론조사 결과를 민심의 척도로 간주하는 것은 과연 일리 있을까?
-   이산사건과 연속사건의 예시를 통해 이에 대한 답을 찾아보자.

## 4. 중심극한정리: 모양이 일그러진 동전

-   앞면 나올 확률이 0.4인 일그러진 동전이 있다.
-   직접 여러 번 던져 앞면이 나올 확률을 계산한 후, 실제 확률인 0.4와의 차이를 살펴보자.

::: columns
::: {.column width="50%"}
```{r,fig.width=10,fig.height=7,warning=F,echo=F}
sample_mean=function(n=10){
  x=rbinom(n,1,0.4)
  return(mean(x))
}


f1=data.frame(n=c("앞면","뒷면"),p=c(0.4,0.6))
g1=ggplot(f1,aes(n,p))+geom_bar(stat = "identity",width=0.3) +ylab("확률")+ggtitle("일그러진 동전의 확률분포")+annotate("text",  x=Inf, y = Inf, label ="평균: 0.4\n분산: 0.24", vjust=1.5, hjust=1)+theme(plot.title = element_text(hjust = 0.5))+theme(axis.text.x = element_text(size=15,face='bold'))


xl=c(0,0.8)
mean_vec=sapply(1:10000,function(x){sample_mean(10)})
legends=paste("평균: ",round(mean(mean_vec),2),"\n분산: ",round(var(mean_vec),4),sep="")
g2=ggplot(data.frame(mean_vec),aes(mean_vec))+geom_histogram(aes(y=..density..),bins=20)+xlim(xl)+xlab("표본평균")+ggtitle("10번 던진 평균들의 분포")+ylab("Density")+annotate("text",  x=Inf, y = Inf, label = legends, vjust=1.5, hjust=1)+theme(plot.title = element_text(hjust = 0.5))+theme(axis.text.x = element_text(size=15,face='bold'))

mean_vec=sapply(1:10000,function(x){sample_mean(30)})
legends=paste("평균: ",round(mean(mean_vec),2),"\n분산: ",round(var(mean_vec),4),sep="")
g3=ggplot(data.frame(mean_vec),aes(mean_vec))+geom_histogram(aes(y=..density..),bins=40)+xlim(xl)+xlab("표본평균")+ggtitle("30번 던진 평균들의 분포")+ylab("Density")+annotate("text",  x=Inf, y = Inf, label = legends, vjust=1.5, hjust=1)+theme(plot.title = element_text(hjust = 0.5))+theme(axis.text.x = element_text(size=15,face='bold'))

mean_vec=sapply(1:10000,function(x){sample_mean(100)})
legends=paste("평균: ",round(mean(mean_vec),2),"\n분산: ",round(var(mean_vec),4),sep="")
g4=ggplot(data.frame(mean_vec),aes(mean_vec))+geom_histogram(aes(y=..density..),bins=90)+geom_density()+xlim(xl)+xlab("표본평균")+ggtitle("100번 던진 평균들의 분포")+ylab("Density")+annotate("text",  x=Inf, y = Inf, label = legends, vjust=1.5, hjust=1)+theme(plot.title = element_text(hjust = 0.5))+theme(axis.text.x = element_text(size=15,face='bold'))

grid.arrange(g1,g2,g3,g4)
```
:::

::: {.column width="50%"}
1.  $n$이 증가할수록 $\hat{p}$의 분포가 정규분포에 가까워진다.
2.  $\hat{p}$의 평균이 실제 $p$값인 0.4에 가까워진다.
3.  $\hat{p}$의 분산이 $\frac{0.24}{n}=\frac{p(1-p)}{n}$에 가까워진다.\
4.  $n$이 커지면 $\hat{p}$은 $N(p,\frac{p(1-p)}{n})$을 따른다.
:::
:::

## 4. 중심극한정리: 주사위 던지기

-   눈의 **평균(**$\mu$): $\frac{1+2+3+4+5+6}{6}=3.5$, **분산(**$\sigma^2$): $\frac{(1-3.5)^2+(2-3.5)^2+\cdots+(6-3.5)^2}{6}\approx 2.92$
-   직접 여러 번 던져 나오는 눈의 평균(표본평균 $\bar{X}$)을 구한 후, 실제 평균($\mu$)과 비교해보자.

::: columns
::: {.column width="50%"}
```{r,fig.width=10,fig.height=7,warning=F,echo=F}
sample_mean=function(n=10){
  x=sample(1:6,n,replace=T)
  return(mean(x))
}

f1=data.frame(n=1:6,p=rep(1/6,6))
g1=ggplot(f1,aes(n,p))+geom_bar(stat = "identity",width=0.7)+xlab("주사위 눈")+ylab("확률")+scale_x_continuous(breaks=1:6)+ylim(0,0.25)+ggtitle("주사위 눈의 확률분포")+annotate("text",  x=Inf, y = Inf, label ="평균: 3.5\n분산: 2.92", vjust=1.5, hjust=1)+theme(plot.title = element_text(hjust = 0.5))+theme(axis.text.x = element_text(size=15,face='bold'))

xl=c(2,5)
mean_vec=sapply(1:10000,function(x){sample_mean(10)})
legends=paste("평균: ",round(mean(mean_vec),2),"\n분산: ",round(var(mean_vec),3),sep="")
g2=ggplot(data.frame(mean_vec),aes(mean_vec))+geom_histogram(aes(y=..density..),bins=30)+geom_density()+xlim(xl)+xlab("표본평균")+ggtitle("10번 던진 평균들의 분포")+ylab("Density")+annotate("text",  x=Inf, y = Inf, label = legends, vjust=1.5, hjust=1)+theme(plot.title = element_text(hjust = 0.5))+theme(axis.text.x = element_text(size=15,face='bold'))

mean_vec=sapply(1:10000,function(x){sample_mean(30)})
legends=paste("평균: ",round(mean(mean_vec),2),"\n분산: ",round(var(mean_vec),3),sep="")
g3=ggplot(data.frame(mean_vec),aes(mean_vec))+geom_histogram(aes(y=..density..),bins=45)+geom_density()+xlim(xl)+xlab("표본평균")+ggtitle("30번 던진 평균들의 분포")+ylab("Density")+annotate("text",  x=Inf, y = Inf, label = legends, vjust=1.5, hjust=1)+theme(plot.title = element_text(hjust = 0.5))+theme(axis.text.x = element_text(size=15,face='bold'))

mean_vec=sapply(1:10000,function(x){sample_mean(100)})
legends=paste("평균: ",round(mean(mean_vec),2),"\n분산: ",round(var(mean_vec),3),sep="")
g4=ggplot(data.frame(mean_vec),aes(mean_vec))+geom_histogram(aes(y=..density..),bins=60)+geom_density()+xlim(xl)+xlab("표본평균")+ggtitle("100번 던진 평균들의 분포")+ylab("Density")+annotate("text",  x=Inf, y = Inf, label = legends, vjust=1.5, hjust=1)+theme(plot.title = element_text(hjust = 0.5))+theme(axis.text.x = element_text(size=15,face='bold'))

grid.arrange(g1,g2,g3,g4)
```
:::

::: {.column width="50%"}
1.  $n$이 증가할수록 표본평균 $\bar{X}$의 분포가 정규분포에 가까워진다.
2.  $\bar{X}$의 평균이 실제 평균인 $\mu=3.5$에 가까워진다.
3.  $\bar{X}$의 분산이 $\frac{2.92}{n}=\frac{\sigma^2}{n}$에 가까워진다.\
4.  $n$이 커지면 $\bar{X}$는 $N(\mu,\frac{\sigma^2}{n})$을 따른다.
:::
:::

## 5. 중심극한정리: 표준정규분포

-   표준 정규분포($\mu=0$, $\sigma^2=1$)에서 $n$개의 숫자를 뽑아 평균을 내는 경우를 살펴보자.

::: columns
::: {.column width="50%"}
```{r,fig.width=10,fig.height=7,warning=F,echo=F}
sample_mean=function(n=30){
  x=rnorm(n)
  return(mean(x))
}

z=seq(-4, 4,0.01)
f3=data.frame(z, p=dnorm(z))
g1=ggplot(f3,aes(z,p))+geom_line()+xlab("z")+ylab("Density")+ggtitle("표준 정규분포의 확률분포")+annotate("text",  x=Inf, y = Inf, label ="평균: 0\n분산: 1", vjust=1.5, hjust=1)+theme(plot.title = element_text(hjust = 0.5))+theme(axis.text.x = element_text(size=15,face='bold'))

xl=c(-.75,.75)
mean_vec=sapply(1:10000,function(x){sample_mean(10)})
legends=paste("평균: ",round(mean(mean_vec),2),"\n분산: ",round(var(mean_vec),3),sep="")
g2=ggplot(data.frame(mean_vec),aes(mean_vec))+geom_histogram(aes(y=..density..),bins=30)+geom_density()+xlim(xl)+xlab("표본평균")+ggtitle("10번 던진 평균들의 분포")+ylab("Density")+annotate("text",  x=Inf, y = Inf, label = legends, vjust=1.5, hjust=1)+theme(plot.title = element_text(hjust = 0.5))+theme(axis.text.x = element_text(size=15,face='bold'))

mean_vec=sapply(1:10000,function(x){sample_mean(30)})
legends=paste("평균: ",round(mean(mean_vec),2),"\n분산: ",round(var(mean_vec),3),sep="")
g3=ggplot(data.frame(mean_vec),aes(mean_vec))+geom_histogram(aes(y=..density..),bins=45)+geom_density()+xlim(xl)+xlab("표본평균")+ggtitle("30번 던진 평균들의 분포")+ylab("Density")+annotate("text",  x=Inf, y = Inf, label = legends, vjust=1.5, hjust=1)+theme(plot.title = element_text(hjust = 0.5))+theme(axis.text.x = element_text(size=15,face='bold'))

mean_vec=sapply(1:10000,function(x){sample_mean(100)})
legends=paste("평균: ",round(mean(mean_vec),2),"\n분산: ",round(var(mean_vec),3),sep="")
g4=ggplot(data.frame(mean_vec),aes(mean_vec))+geom_histogram(aes(y=..density..),bins=80)+geom_density()+xlim(xl)+xlab("표본평균")+ggtitle("100번 던진 평균들의 분포")+ylab("Density")+ylab("Density")+annotate("text",  x=Inf, y = Inf, label = legends, vjust=1.5, hjust=1)+theme(plot.title = element_text(hjust = 0.5))+theme(axis.text.x = element_text(size=15,face='bold'))

grid.arrange(g1,g2,g3,g4)
```
:::

::: {.column width="50%"}
1.  $n$이 증가할수록 표본평균 $\bar{X}$의 분포가 정규분포에 가까워진다.
2.  $\bar{X}$의 평균이 실제 평균 0에,\
3.  $\bar{X}$의 분산이 $\frac{1}{n}$에 가까워졌다.\
4.  **즉 연속확률의 경우에도** $n$이 커지면 $\bar{X}$는 $N(\mu,\frac{\sigma^2}{n})$을 따른다.
:::
:::

## 5. 중심극한정리: 카이제곱분포

-   자유도가 1인 카이제곱분포: 왼쪽으로 치우친 분포\
-   위 카이제곱분포($\mu=1$, $\sigma^2=2$)에서 $n$개의 숫자를 뽑아 평균을 내는 경우를 살펴보자.

::: columns
::: {.column width="50%"}
```{r,fig.width=10,fig.height=7,warning=F,echo=F}
sample_mean=function(n=30){
  x=rchisq(n,df=1)
  return(mean(x))
}

z=seq(0.5, 8,0.01)
f3=data.frame(z, p=dchisq(z,df=1))
g1=ggplot(f3,aes(z,p))+geom_line()+xlab("z")+ylab("Density")+ggtitle("카이제곱분포(자유도 1) 의 확률분포")+annotate("text",  x=Inf, y = Inf, label ="평균: 1\n분산: 2", vjust=1.5, hjust=1)+theme(plot.title = element_text(hjust = 0.5))+theme(axis.text.x = element_text(size=15,face='bold'))

xl=c(0,2)
mean_vec=sapply(1:10000,function(x){sample_mean(10)})
legends=paste("평균: ",round(mean(mean_vec),2),"\n분산: ",round(var(mean_vec),3),sep="")
g2=ggplot(data.frame(mean_vec),aes(mean_vec))+geom_histogram(aes(y=..density..),bins=50)+geom_density()+xlim(xl)+xlab("표본평균")+ggtitle("10번 던진 평균들의 분포")+ylab("Density")+annotate("text",  x=Inf, y = Inf, label = legends, vjust=1.5, hjust=1)+theme(plot.title = element_text(hjust = 0.5))+theme(axis.text.x = element_text(size=15,face='bold'))

mean_vec=sapply(1:10000,function(x){sample_mean(30)})
legends=paste("평균: ",round(mean(mean_vec),2),"\n분산: ",round(var(mean_vec),3),sep="")
g3=ggplot(data.frame(mean_vec),aes(mean_vec))+geom_histogram(aes(y=..density..),bins=100)+geom_density()+xlim(xl)+xlab("표본평균")+ggtitle("30번 던진 평균들의 분포")+ylab("Density")+annotate("text",  x=Inf, y = Inf, label = legends, vjust=1.5, hjust=1)+theme(plot.title = element_text(hjust = 0.5))+theme(axis.text.x = element_text(size=15,face='bold'))

mean_vec=sapply(1:10000,function(x){sample_mean(100)})
legends=paste("평균: ",round(mean(mean_vec),2),"\n분산: ",round(var(mean_vec),3),sep="")
g4=ggplot(data.frame(mean_vec),aes(mean_vec))+geom_histogram(aes(y=..density..),bins=200)+geom_density()+xlim(xl)+xlab("표본평균")+ggtitle("100번 던진 평균들의 분포")+ylab("Density")+annotate("text",  x=Inf, y = Inf, label = legends, vjust=1.5, hjust=1)+theme(plot.title = element_text(hjust = 0.5))+theme(axis.text.x = element_text(size=15,face='bold'))

grid.arrange(g1,g2,g3,g4)
```
:::

::: {.column width="50%"}
1.  $n$이 증가할수록 $\bar{X}$의 분포가 정규분포에 가까워진다.
2.  $\bar{X}$의 평균과 분산이 각각 1, $\frac{2}{n}$에 가까워졌다.\
3.  모집단에서 $n$개의 표본을 뽑아 계산한 $\bar{X}$는 $n$이 커질수록 $N(\mu,\frac{\sigma^2}{n})$을 따른다.
4.  **중심극한정리(Central Limit Theorem, CLT)** : 어떤 모집단이든 30개 정도의 $\bar{X}$가 확보되면 정규분포를 따른다.
:::
:::

## 6. 중심극한정리 고찰(1) - 쪽수가 깡패(?)다

-   중심극한정리의 중요성은 정규분포와의 관계 외에도 충분히 설명된다.\
-   표본평균의 평균이 모집단 평균에 가까워지는 것과
-   표본평균의 분산이 모집단 분산을 $n$으로 나눈 $\frac{\sigma^2}{n}$이 된다는 것에서 우리는 무엇을 깨달을 수 있을까?
-   바로, **쪽수가 깡패(?)**라는 것이다.
-   $n$이 커질수록 표본평균의 분산이 점점 0에 가까워지게 되어 표본평균을 그냥 실제평균으로 간주해도 문제가 없게 된다.

## 6. 중심극한정리 고찰(2) - 의심의 정도 숫자로 표현 가능

-   표본확률 평균의 분포가 $N(0.4,0.024)$에 가까워 지는 일그러진 동전의 예를 떠올려보자.
-   계산해서 나온 확률과 실제 확률 0.4와의 차이를 어떻게 받아들여야 하는가?
-   우리는 **중심극한정리를 통해 의심의 정도를 숫자로 표현할 수 있다.**
    -   10번 중 앞면이 6번 이상 나올 확률: 19.7% $\div2$ = 9.85% -\> 그럴 수 있지.
    -   30번 중 앞면이 18번 이상 나올 확률: 2.5% $\div2$ = 1.25% -\> 좀 이상한데?
    -   100번 중 앞면이 60번 이상 나올 확률: 0.004% $\div2$ = 0.002% -\> 이건 거짓말이다!

```{r,fig.width=15,fig.height=3,warning=F,echo=F}
sample_mean=function(n=10){
  x=rbinom(n,1,0.4)
  return(mean(x))
}

z=seq(0,0.8,0.01)
d10=dnorm(z,mean=0.4,sd=sqrt(0.024))
d30=dnorm(z,mean=0.4,sd=sqrt(0.008))
d100=dnorm(z,mean=0.4,sd=sqrt(0.0024))
pct10=1-2*pnorm(0.2,mean=0.4,sd=sqrt(0.024));pct10=paste(round(100*pct10,1),"%",sep="")
pct30=1-2*pnorm(0.2,mean=0.4,sd=sqrt(0.008));pct30=paste(round(100*pct30,1),"%",sep="")
pct100=1-2*pnorm(0.2,mean=0.4,sd=sqrt(0.0024));pct100=paste(round(100*pct100,3),"%",sep="")


f1=data.frame(n=c("앞면","뒷면"),p=c(0.4,0.6))
g1=ggplot(f1,aes(n,p))+geom_bar(stat = "identity",width=0.3) +ylab("확률")+ggtitle("찌그러진 동전 던지기의 확률분포")+annotate("text",  x=Inf, y = Inf, label ="평균: 0.4\n분산: 0.24", vjust=1.5, hjust=1)


xl=c(0,0.8)
g2=ggplot(data.frame(z,d10),aes(z,d10))+geom_line()+xlim(xl)+xlab("표본평균")+ggtitle("10번 던진 평균들")+ylab("Density")+ geom_ribbon(data=subset(data.frame(z,d10), z>=0.2 & z<=0.6),aes(x=z,ymax=d10),ymin=0,fill="red", alpha=0.5)+geom_text(data = NULL, x = 0.4, y = 0.4, label = pct10,size=6)+theme(plot.title = element_text(hjust = 0.5))+theme(axis.text.x = element_text(size=15,face='bold'))+geom_vline(xintercept = 0.6, color = "red", linetype = 2)

g3=ggplot(data.frame(z,d30),aes(z,d30))+geom_line()+xlim(xl)+xlab("표본평균")+ggtitle("30번 던진 평균들")+ylab("Density")+geom_ribbon(data=subset(data.frame(z,d30), z>=0.2 & z<=0.6),aes(x=z,ymax=d30),ymin=0,fill="red", alpha=0.5)+geom_text(data = NULL, x = 0.4, y = 0.5, label = pct30,size=6)+theme(plot.title = element_text(hjust = 0.5))+theme(axis.text.x = element_text(size=15,face='bold'))+geom_vline(xintercept = 0.6, color = "red", linetype = 2)

g4=ggplot(data.frame(z,d100),aes(z,d100))+geom_line()+xlim(xl)+xlab("표본평균")+ggtitle("100번 던진 평균들")+ylab("Density")+geom_ribbon(data=subset(data.frame(z,d100), z>=0.2 & z<=0.6),aes(x=z,ymax=d100),ymin=0,fill="red", alpha=0.5)+geom_text(data = NULL, x = 0.4, y = 1, label = pct100,size=6)+theme(plot.title = element_text(hjust = 0.5))+theme(axis.text.x = element_text(size=15,face='bold'))+geom_vline(xintercept = 0.6, color = "red", linetype = 2)


grid.arrange(g2,g3,g4,ncol=3)
```

## 7. Conclusion

-   정규분포의 중요성을 뒷받침하는 3개의 근거와 중심극한정리의 의미를 살펴보았다.
-   다시 한 번 아래 내용을 되새기며 **정규분포**에 대한 개념을 짚고 넘어가기를 바란다.

<center>

**정규분포의 당위성**

> by **이항분포**

> by **오차의 법칙**

> by **중심극한정리**

> 시행 횟수/표본 개수 $n$이 커질수록 **표본평균** $\bar{X}$는 $N(\mu,\frac{\sigma^2}{n})$을 따른다.
